setwd('D:/')
setwd("D:/New folder/dataset/K_Means/K_Means")
dataset = read.csv('Mall_Customers.csv')
View(dataset)
X <-dataset[4:5]
#elbow method to find optimal clusters
set.seed(6)
wcss <- vector()
plot(1:10,wcss,type = 'b',
main = paste('Cluster of clients'),
xlab = 'Number of Clusters',
ylab = 'WCSS')
set.seed(6)
wcss <- vector()
for (i in 1:10) wcss[i] <-sum(kmeans(X,i)$withinss)
for (i in 1:10) wcss[i] <-sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type = 'b',
main = paste('Cluster of clients'),
xlab = 'Number of Clusters',
ylab = 'WCSS')
#visualising
library(cluster)
clusplot(X,
clus = kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 4  ,
plotchar = FALSE,
span = TRUE,
main = 'Cluster of clients',
xlab = 'Annual Spend',
ylab = 'Spending Score')
library(cluster)
clusplot(X,
clus = kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2   ,
plotchar = FALSE,
span = TRUE,
main = 'Cluster of clients',
xlab = 'Annual Spend',
ylab = 'Spending Score')
y_kmeans=kmeans$cluster
# K-Means Clustering
# Importing the dataset
dataset = read.csv('Mall_Customers.csv')
dataset = dataset[4:5]
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Using the elbow method to find the optimal number of clusters
set.seed(6)
wcss = vector()
for (i in 1:10) wcss[i] = sum(kmeans(dataset, i)$withinss)
plot(1:10,
wcss,
type = 'b',
main = paste('The Elbow Method'),
xlab = 'Number of clusters',
ylab = 'WCSS')
# Fitting K-Means to the dataset
set.seed(29)
kmeans = kmeans(x = dataset, centers = 5)
y_kmeans = kmeans$cluster
# Visualising the clusters
library(cluster)
clusplot(dataset,
y_kmeans,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
set.seed(29)
kmeans <-kmeans(X,5,iter.max = 300,nstart = 10)
#visualising
library(cluster)
clusplot(X,
clus = kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = 'Cluster of clients',
xlab = 'Annual Spend',
ylab = 'Spending Score')
library(cluster)
clusplot(X,
clus = kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 4,
plotchar = FALSE,
span = TRUE,
main = 'Cluster of clients',
xlab = 'Annual Spend',
ylab = 'Spending Score')
y_kmeans=kmeans$cluster
setwd("D:/New folder/dataset/Hierarchical-Clustering/Hierarchical_Clustering")
#import data
dataset=read.csv('Mall_Customers.csv')
View(dataset)
View(dataset)
View(dataset)
View(dataset)
X <-dataset[4:5]
View(X)
View(X)
dist(X,method = 'euclidean')
dendrogram=hclust(dist(X,method = 'euclidean'),method = 'ward.D')
plot(dendrogram,main='Dendrogram',xlab='Customers',ylab = 'Euclidean Distances')
hc=hclust(dist(X,method = 'euclidean'),method = 'ward.D')
y_hc=cutree(hc,5)
View(hc)
y_hc
union(hc)
union(y_hc)
unique(y_hc)
#Visualising
library('cusplot')
#Visualising
library('cluster')
library('cluster')
clusplot(X,
clus = y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 4,
plotchar = FALSE,
span = TRUE,
main = 'Clustering',
xlab = 'Customers',
ylab = 'Spending Score ')
